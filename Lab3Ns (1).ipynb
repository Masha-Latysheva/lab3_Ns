{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторная работа №3"
      ],
      "metadata": {
        "id": "D-1kseNHGwPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krROzK7PzxJ9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "cup1 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup2 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup3 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup4 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup5 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "butle1 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle2 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle3 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle4 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle5 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "def get_cup():\n",
        "    return np.array([cup1, cup2, cup3, cup4, cup5])\n",
        "\n",
        "def get_butle():\n",
        "    return np.array([butle1, butle2, butle3, butle4, butle5])\n",
        "\n",
        "def get_conv_numbers(number):\n",
        "    if number == 1:\n",
        "        return [[np.sum(row) for row in num] for num in get_butle().reshape(5, 5, 5)]\n",
        "    elif number == 0:\n",
        "        return [[np.sum(row) for row in num] for num in get_cup().reshape(5, 5, 5)]\n",
        "    else:\n",
        "        raise Exception(\"Нет такой цифры, введите либо чашку либо бутылку\")\n",
        "\n",
        "def get_conv_number(number):\n",
        "    return np.array([np.sum(row) for row in number.reshape(5, 5)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, accuracy_score\n",
        "\n",
        "def add_bias_feature(a):\n",
        "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
        "    a_extended[:,:-1] = a\n",
        "    a_extended[:,-1] = int(1)  \n",
        "    return a_extended\n",
        "\n",
        "class SVM(object):\n",
        "    def __init__(self, etha=0.01, alpha=0.1, epochs=200):\n",
        "        self._epochs = epochs\n",
        "        self._etha = etha\n",
        "        self._alpha = alpha\n",
        "        self._w = None # Веса модели\n",
        "        self.history_w = [] # История изменения весов для показа\n",
        "        self.train_errors = None # Ошибки обучения модели\n",
        "        self.val_errors = None # Ошибки проверки качества модели\n",
        "        self.train_loss = None # Значение функции потерь модели при обучении\n",
        "        self.val_loss = None # Значение функции потерь модели при проверке\n",
        "\n",
        "    def fit(self, X_train, Y_train, X_val, Y_val, verbose=False): #arrays: X; Y =-1,1\n",
        "        '''\n",
        "        Метод обучения модели, значения массивов y принимают значения либо 1 либо -1\n",
        "        1 - если на выходе должна быть еденица, -1 если ноль \n",
        "        '''\n",
        "        if len(set(Y_train)) != 2 or len(set(Y_val)) != 2: # Проверка, что бы количество классов было равно 2 (бин классификация)\n",
        "            raise ValueError(\"Number of classes in Y is not equal 2!\")\n",
        "\n",
        "        X_train = add_bias_feature(X_train) # Добавление признака смещения в каждый столбец\n",
        "        X_val = add_bias_feature(X_val)\n",
        "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1]) # Инициализируем веса случайными значениями\n",
        "        self.history_w.append(self._w) # Записываем начальные веса в историю весов\n",
        "        # Инициализируем списки\n",
        "        train_errors = []\n",
        "        val_errors = []\n",
        "        train_loss_epoch = []\n",
        "        val_loss_epoch = []\n",
        "        # Начало тренировки модели\n",
        "        for epoch in range(self._epochs):\n",
        "            tr_err = 0\n",
        "            val_err = 0\n",
        "            tr_loss = 0\n",
        "            val_loss = 0\n",
        "            for i,x in enumerate(X_train): # Индексируем элементы обучающей выборки\n",
        "                margin = Y_train[i]*np.dot(self._w,X_train[i]) # Находим значение отступа модели\n",
        "                if margin >= 1: # классифицируем верно, если отступ элемента больше радиуса полосы модели\n",
        "                    self._w -= self._etha*self._alpha*self._w/self._epochs # Изменяем веса пропорционально эпохе обучения\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i]) # Увеличения значерия потерь\n",
        "                else: # классифицируем неверно или попадаем на полосу разделения при 0<m<1\n",
        "                    self._w += self._etha*(Y_train[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
        "                    tr_err += 1\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
        "                self.history_w.append(self._w)\n",
        "            for i,x in enumerate(X_val): # Цикл проверки качества модели\n",
        "                val_loss += self.soft_margin_loss(X_val[i], Y_val[i])\n",
        "                val_err += (Y_val[i]*np.dot(self._w,X_val[i])<1).astype(int)\n",
        "            if verbose and epoch % 20 == 0:\n",
        "                print('epoch {}. Errors={}. Mean Hinge_loss={}'\\\n",
        "                      .format(epoch,val_err, val_loss))\n",
        "            train_errors.append(tr_err)\n",
        "            val_errors.append(val_err)\n",
        "            train_loss_epoch.append(tr_loss)\n",
        "            val_loss_epoch.append(val_loss)\n",
        "        self.history_w = np.array(self.history_w)    \n",
        "        self.train_errors = np.array(train_errors)\n",
        "        self.val_errors = np.array(val_errors)\n",
        "        self.train_loss = np.array(train_loss_epoch)\n",
        "        self.val_loss = np.array(val_loss_epoch)                    \n",
        "\n",
        "    def predict(self, X:np.array) -> np.array:\n",
        "        y_pred = []\n",
        "        X_extended = add_bias_feature(X)\n",
        "        for i in range(len(X_extended)):\n",
        "            y_pred.append(np.sign(np.dot(self._w,X_extended[i])))\n",
        "        return np.array(y_pred)         \n",
        "\n",
        "    def hinge_loss(self, x, y):\n",
        "        return max(0,1 - y*np.dot(x, self._w))\n",
        "\n",
        "    def soft_margin_loss(self, x, y):\n",
        "        return self.hinge_loss(x,y)+self._alpha*np.dot(self._w, self._w)\n",
        "\n",
        "\n",
        "svm = SVM(epochs=1000)\n",
        "svm.fit(np.vstack([get_conv_numbers(0), get_conv_numbers(1)]), np.array([-1,-1,-1,-1,-1,1,1,1,1,1]),\n",
        "        np.vstack([get_conv_numbers(0)[3:], get_conv_numbers(1)[3:]]), np.array([-1,-1,-1,1,1,1]),\n",
        "        verbose=True)\n",
        "# Предсказать число, если чашка то output = -1, иначе 1\n",
        "number =  np.array([0,1,0,0,0,\n",
        "                    1,0,1,1,0,\n",
        "                    1,1,1,0,1,\n",
        "                    1,0,1,1,0,\n",
        "                    1,1,1,0,0])\n",
        "\n",
        "y_pred = svm.predict(np.array([get_conv_number(number)]))\n",
        "\n",
        "print(\"Class: \" + str(svm.predict(np.array([get_conv_number(number)]))))\n",
        "print(\"Accuracy: \" + str(accuracy_score(cup3, number)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhQ4xhvzxgu",
        "outputId": "46f4250d-faca-4193-d7a2-6c3651d0ad53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0. Errors=4. Mean Hinge_loss=5.29849363743798\n",
            "epoch 20. Errors=1. Mean Hinge_loss=2.2874965237610754\n",
            "epoch 40. Errors=1. Mean Hinge_loss=2.287188537047287\n",
            "epoch 60. Errors=1. Mean Hinge_loss=2.2868806321258965\n",
            "epoch 80. Errors=1. Mean Hinge_loss=2.286572808972467\n",
            "epoch 100. Errors=1. Mean Hinge_loss=2.2862650675625673\n",
            "epoch 120. Errors=1. Mean Hinge_loss=2.2859574078717806\n",
            "epoch 140. Errors=1. Mean Hinge_loss=2.2856498298756946\n",
            "epoch 160. Errors=1. Mean Hinge_loss=2.2853423335499063\n",
            "epoch 180. Errors=1. Mean Hinge_loss=2.28503491887002\n",
            "epoch 200. Errors=1. Mean Hinge_loss=2.2847275858116487\n",
            "epoch 220. Errors=1. Mean Hinge_loss=2.284420334350415\n",
            "epoch 240. Errors=1. Mean Hinge_loss=2.2841131644619477\n",
            "epoch 260. Errors=1. Mean Hinge_loss=2.2838060761218837\n",
            "epoch 280. Errors=1. Mean Hinge_loss=2.283499069305868\n",
            "epoch 300. Errors=1. Mean Hinge_loss=2.283192143989557\n",
            "epoch 320. Errors=1. Mean Hinge_loss=2.2828853001486045\n",
            "epoch 340. Errors=1. Mean Hinge_loss=2.2825785377586865\n",
            "epoch 360. Errors=1. Mean Hinge_loss=2.28227185679548\n",
            "epoch 380. Errors=1. Mean Hinge_loss=2.2819652572346683\n",
            "epoch 400. Errors=1. Mean Hinge_loss=2.281658739051948\n",
            "epoch 420. Errors=1. Mean Hinge_loss=2.2813523022230195\n",
            "epoch 440. Errors=1. Mean Hinge_loss=2.2810459467235935\n",
            "epoch 460. Errors=1. Mean Hinge_loss=2.2807396725293887\n",
            "epoch 480. Errors=1. Mean Hinge_loss=2.280433479616128\n",
            "epoch 500. Errors=1. Mean Hinge_loss=2.280127367959547\n",
            "epoch 520. Errors=1. Mean Hinge_loss=2.279821337535389\n",
            "epoch 540. Errors=1. Mean Hinge_loss=2.279515388319406\n",
            "epoch 560. Errors=1. Mean Hinge_loss=2.2792095202873535\n",
            "epoch 580. Errors=1. Mean Hinge_loss=2.278903733414997\n",
            "epoch 600. Errors=1. Mean Hinge_loss=2.2785980276781124\n",
            "epoch 620. Errors=1. Mean Hinge_loss=2.2782924030524816\n",
            "epoch 640. Errors=1. Mean Hinge_loss=2.277986859513896\n",
            "epoch 660. Errors=1. Mean Hinge_loss=2.2776813970381546\n",
            "epoch 680. Errors=1. Mean Hinge_loss=2.2773760156010616\n",
            "epoch 700. Errors=1. Mean Hinge_loss=2.277070715178431\n",
            "epoch 720. Errors=1. Mean Hinge_loss=2.2767654957460906\n",
            "epoch 740. Errors=1. Mean Hinge_loss=2.276460357279866\n",
            "epoch 760. Errors=1. Mean Hinge_loss=2.2761552997555965\n",
            "epoch 780. Errors=1. Mean Hinge_loss=2.275850323149133\n",
            "epoch 800. Errors=1. Mean Hinge_loss=2.275545427436324\n",
            "epoch 820. Errors=1. Mean Hinge_loss=2.2752406125930382\n",
            "epoch 840. Errors=1. Mean Hinge_loss=2.2749358785951435\n",
            "epoch 860. Errors=1. Mean Hinge_loss=2.274631225418517\n",
            "epoch 880. Errors=1. Mean Hinge_loss=2.2743266530390467\n",
            "epoch 900. Errors=1. Mean Hinge_loss=2.2740221614326273\n",
            "epoch 920. Errors=1. Mean Hinge_loss=2.273717750575161\n",
            "epoch 940. Errors=1. Mean Hinge_loss=2.2734134204425596\n",
            "epoch 960. Errors=1. Mean Hinge_loss=2.2731091710107414\n",
            "epoch 980. Errors=1. Mean Hinge_loss=2.272805002255633\n",
            "Class: [-1.]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRMGNtYJzxiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}